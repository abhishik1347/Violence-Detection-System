{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 08m 55s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 02h 11m 08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhishik chebrolu\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the CNN...\n",
      "Training on data with shape: (6800, 224, 224, 3)\n",
      "Epoch 1/15\n",
      "\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 475ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 462ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 462ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 475ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the CNN...\n",
      "Testing on data with shape: (9200, 224, 224, 3)\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 332ms/step\n",
      "Predicted classes: [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load the UCSD Pedestrian dataset\n",
    "def load_ucsd_pedestrian_dataset(train_path, test_path, image_size):\n",
    "    train_images = []  # Normal frames (Train set, label = 0)\n",
    "    train_labels = []\n",
    "\n",
    "    test_images = []  # Test frames (no labels, unsupervised anomaly detection)\n",
    "\n",
    "    # Load normal frames from Train folder (all labeled as 0)\n",
    "    for dirpath, _, filenames in os.walk(train_path):\n",
    "        for file in filenames:\n",
    "            if file.endswith(('.jpg', '.png', '.tif')):\n",
    "                image_path = os.path.join(dirpath, file)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    image = cv2.resize(image, image_size)  # Resizing to hyperparameter-controlled size\n",
    "                    image = image.astype('float32') / 255.0\n",
    "                    train_images.append(image)\n",
    "                    train_labels.append(0)  # Normal frames = 0\n",
    "    \n",
    "    # Load Test frames (no labels provided)\n",
    "    for dirpath, _, filenames in os.walk(test_path):\n",
    "        for file in filenames:\n",
    "            if file.endswith(('.jpg', '.png', '.tif', '.bmp')):\n",
    "                image_path = os.path.join(dirpath, file)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    image = cv2.resize(image, image_size)\n",
    "                    image = image.astype('float32') / 255.0\n",
    "                    test_images.append(image)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_images = np.array(test_images)\n",
    "\n",
    "    print(f\"Loaded {len(train_images)} training images and {len(test_images)} testing images.\")\n",
    "    return train_images, train_labels, test_images\n",
    "\n",
    "# CNN Model with Fixed Output Size After Flattening\n",
    "def create_cnn_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tunable number of filters for each Conv2D layer\n",
    "    model.add(Conv2D(filters=hp.Int('filters_1', 32, 128, step=32), kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=hp.Int('filters_2', 64, 256, step=64), kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=hp.Int('filters_3', 128, 512, step=128), kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten the output to match the input size of the dense layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Calculate the output size after Flattening (using a fixed image size)\n",
    "    model.add(Dense(units=hp.Int('dense_units_1', 128, 512, step=128), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', 0.2, 0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Dense(units=hp.Int('dense_units_2', 64, 256, step=64), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Use sigmoid for binary classification\n",
    "    \n",
    "    # Compile the model with a tunable learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Hyperparameter tuning using Keras Tuner\n",
    "def tune_hyperparameters(train_images, train_labels):\n",
    "    tuner = RandomSearch(\n",
    "        create_cnn_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=5,\n",
    "        executions_per_trial=1,\n",
    "        directory='cnn_tuning',\n",
    "        project_name='ucsd_pedestrian_tuning'\n",
    "    )\n",
    "\n",
    "    # Run the search\n",
    "    tuner.search(train_images, train_labels, epochs=5, validation_split=0.2)\n",
    "    \n",
    "    # Get the best model after tuning\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Train the CNN model\n",
    "def train_cnn(model, train_images, train_labels, batch_size, epochs):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    print(f\"Training on data with shape: {train_images.shape}\")\n",
    "    \n",
    "    history = model.fit(train_images, train_labels,  # Train on images and their corresponding labels\n",
    "                        validation_split=0.3,  # Using 30% of training data for validation\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stopping])\n",
    "    return history\n",
    "\n",
    "# Test the model on the test dataset (no labels)\n",
    "def test_cnn(model, test_images):\n",
    "    print(f\"Testing on data with shape: {test_images.shape}\")\n",
    "    \n",
    "    # Predict classes\n",
    "    predictions = model.predict(test_images)\n",
    "    predicted_classes = (predictions > 0.5).astype(\"int32\")  # Thresholding for binary classification\n",
    "    \n",
    "    print(f\"Predicted classes: {predicted_classes.flatten()}\")\n",
    "    \n",
    "    return predicted_classes\n",
    "\n",
    "# Main function to execute the workflow for UCSD dataset\n",
    "def main():\n",
    "    train_path = r'C:\\Users\\abhishik chebrolu\\Downloads\\AINN pro\\UCSD_Anomaly_Dataset\\UCSD_Anomaly_Dataset.v1p2\\UCSDped1\\Train'  # Path to the Train folder\n",
    "    test_path = r'C:\\Users\\abhishik chebrolu\\Downloads\\AINN pro\\UCSD_Anomaly_Dataset\\UCSD_Anomaly_Dataset.v1p2\\UCSDped1\\Test'  # Path to the Test folder\n",
    "    \n",
    "    # Load the dataset without labels for test data\n",
    "    image_size = (224, 224)  # Default image size (fixed for now to avoid shape mismatches)\n",
    "    train_images, train_labels, test_images = load_ucsd_pedestrian_dataset(train_path, test_path, image_size)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    best_model = tune_hyperparameters(train_images, train_labels)\n",
    "    \n",
    "    # Train the CNN\n",
    "    batch_size = 8\n",
    "    epochs = 15\n",
    "    print(\"Training the CNN...\")\n",
    "    history = train_cnn(best_model, train_images, train_labels, batch_size, epochs)\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    # Test the CNN and get predictions\n",
    "    print(\"Testing the CNN...\")\n",
    "    predicted_classes = test_cnn(best_model, test_images)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\__init__.py:47\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     45\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_util\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\_api\\v2\\__internal__\\feature_column\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.feature_column namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenseColumn \u001b[38;5;66;03m# line: 1777\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeatureTransformationCache \u001b[38;5;66;03m# line: 1962\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequenceDenseColumn \u001b[38;5;66;03m# line: 1941\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m readers\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column \u001b[38;5;28;01mas\u001b[39;00m fc_old\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column_v2_types \u001b[38;5;28;01mas\u001b[39;00m fc_types\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_column\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m sparse_tensor_lib\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops_stack\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\layers\\base.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_tf_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[0;32m     18\u001b[0m InputSpec \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mInputSpec\n\u001b[0;32m     20\u001b[0m keras_style_scope \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mkeras_style_scope\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\keras\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\keras\\models.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_module\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sequential\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m network_serialization\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks \u001b[38;5;28;01mas\u001b[39;00m callbacks_module\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizers\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\keras\\callbacks.py:47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributed_file_utils\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m worker_training_state\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m learning_rate_schedule\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\keras\\distribute\\worker_training_state.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributed_file_utils\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mode_keys\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_io\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variables\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:991\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1087\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1187\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Function to load the UCSD Pedestrian dataset\n",
    "def load_ucsd_pedestrian_dataset(train_path, test_path, image_size):\n",
    "    train_images = []  # Normal frames (Train set, label = 0)\n",
    "    train_labels = []\n",
    "\n",
    "    test_images = []  # Test frames (no labels, unsupervised anomaly detection)\n",
    "    test_labels = []  # Optional: Add ground truth labels here if available\n",
    "\n",
    "    # Load normal frames from Train folder (all labeled as 0)\n",
    "    for dirpath, _, filenames in os.walk(train_path):\n",
    "        for file in filenames:\n",
    "            if file.endswith(('.jpg', '.png', '.tif', '.bmp')):\n",
    "                image_path = os.path.join(dirpath, file)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    image = cv2.resize(image, image_size)  # Resizing to hyperparameter-controlled size\n",
    "                    image = image.astype('float32') / 255.0\n",
    "                    train_images.append(image)\n",
    "                    train_labels.append(0)  # Normal frames = 0\n",
    "    \n",
    "    # Load Test frames (assuming no labels for now, but if you have labels, update accordingly)\n",
    "    for dirpath, _, filenames in os.walk(test_path):\n",
    "        for file in filenames:\n",
    "            if file.endswith(('.jpg', '.png', '.tif', '.bmp')):\n",
    "                image_path = os.path.join(dirpath, file)\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    image = cv2.resize(image, image_size)\n",
    "                    image = image.astype('float32') / 255.0\n",
    "                    test_images.append(image)\n",
    "                    test_labels.append(1)  # If you have test labels, assign accordingly\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    print(f\"Loaded {len(train_images)} training images and {len(test_images)} testing images.\")\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# CNN Model with Fixed Output Size After Flattening\n",
    "def create_cnn_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tunable number of filters for each Conv2D layer\n",
    "    model.add(Conv2D(filters=hp.Int('filters_1', 32, 128, step=32), kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=hp.Int('filters_2', 64, 256, step=64), kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=hp.Int('filters_3', 128, 512, step=128), kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten the output to match the input size of the dense layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Calculate the output size after Flattening (using a fixed image size)\n",
    "    model.add(Dense(units=hp.Int('dense_units_1', 128, 512, step=128), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', 0.2, 0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Dense(units=hp.Int('dense_units_2', 64, 256, step=64), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Use sigmoid for binary classification\n",
    "    \n",
    "    # Compile the model with a tunable learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Hyperparameter tuning using Keras Tuner\n",
    "def tune_hyperparameters(train_images, train_labels):\n",
    "    tuner = RandomSearch(\n",
    "        create_cnn_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=2,\n",
    "        executions_per_trial=1,\n",
    "        directory='cnn_tuning',\n",
    "        project_name='ucsd_pedestrian_tuning'\n",
    "    )\n",
    "\n",
    "    # Run the search\n",
    "    tuner.search(train_images, train_labels, epochs=5, validation_split=0.2)\n",
    "    \n",
    "    # Get the best model after tuning\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Train the CNN model\n",
    "def train_cnn(model, train_images, train_labels, batch_size, epochs):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    print(f\"Training on data with shape: {train_images.shape}\")\n",
    "    \n",
    "    history = model.fit(train_images, train_labels,  # Train on images and their corresponding labels\n",
    "                        validation_split=0.3,  # Using 30% of training data for validation\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stopping])\n",
    "    return history\n",
    "\n",
    "# Test the model on the test dataset and calculate accuracy + AUC\n",
    "def test_cnn_with_metrics(model, test_images, test_labels):\n",
    "    print(f\"Testing on data with shape: {test_images.shape}\")\n",
    "    \n",
    "    # Predict probabilities (for AUC)\n",
    "    predictions = model.predict(test_images).flatten()\n",
    "    \n",
    "    # Predicted classes (for accuracy)\n",
    "    predicted_classes = (predictions > 0.5).astype(\"int32\")\n",
    "    \n",
    "    print(f\"Predicted classes: {predicted_classes}\")\n",
    "    \n",
    "    # Calculate accuracy if test labels are available\n",
    "    if test_labels is not None:\n",
    "        accuracy = accuracy_score(test_labels, predicted_classes)\n",
    "        auc = roc_auc_score(test_labels, predictions)\n",
    "        print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"Test AUC: {auc:.2f}\")\n",
    "        return accuracy, auc\n",
    "    else:\n",
    "        print(\"No test labels provided, unable to calculate accuracy or AUC.\")\n",
    "        return None, None\n",
    "\n",
    "# Main function to execute the workflow for UCSD dataset\n",
    "def main():\n",
    "    train_path = r'C:\\Users\\abhishik chebrolu\\Downloads\\AINN pro\\UCSD_Anomaly_Dataset\\UCSD_Anomaly_Dataset.v1p2\\UCSDped1\\Train'  # Path to the Train folder\n",
    "    test_path = r'C:\\Users\\abhishik chebrolu\\Downloads\\AINN pro\\UCSD_Anomaly_Dataset\\UCSD_Anomaly_Dataset.v1p2\\UCSDped1\\Test'  # Path to the Test folder\n",
    "    \n",
    "    # Load the dataset without labels for test data\n",
    "    image_size = (224, 224)  # Default image size (fixed for now to avoid shape mismatches)\n",
    "    train_images, train_labels, test_images, test_labels = load_ucsd_pedestrian_dataset(train_path, test_path, image_size)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    best_model = tune_hyperparameters(train_images, train_labels)\n",
    "    \n",
    "    # Train the CNN\n",
    "    batch_size = 8\n",
    "    epochs = 10\n",
    "    print(\"Training the CNN...\")\n",
    "    history = train_cnn(best_model, train_images, train_labels, batch_size, epochs)\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    # Test the CNN and get predictions + accuracy + AUC (if test labels are available)\n",
    "    print(\"Testing the CNN...\")\n",
    "    test_accuracy, test_auc = test_cnn_with_metrics(best_model, test_images, test_labels)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
